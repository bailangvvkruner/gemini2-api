# ðŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

## ä¸€è¡Œå‘½ä»¤å¯åŠ¨ï¼ˆæœ€ç®€å•ï¼‰

```bash
docker run -d --name gemini-proxy --restart unless-stopped -p 8080:8080 -e BEARER_TOKEN="YOUR_TOKEN" -e CONFIG_ID="YOUR_CONFIG" ghcr.io/yourusername/gemini-proxy:latest
```

## å®Œæ•´æ­¥éª¤

### 1ï¸âƒ£ èŽ·å–é…ç½®

**Bearer Token:**
1. æ‰“å¼€ [Gemini Business](https://business.gemini.google)
2. æŒ‰ F12 â†’ Network æ ‡ç­¾
3. å‘é€æ¶ˆæ¯ï¼Œæ‰¾åˆ° `widgetStreamAssist` è¯·æ±‚
4. å¤åˆ¶ Request Headers ä¸­çš„ `Authorization: Bearer eyJhbGci...`

**Config ID:**
ä»ŽURLå¤åˆ¶ï¼š`https://business.gemini.google/home/cid/CONFIG_ID/...`

### 2ï¸âƒ£ è¿è¡Œå®¹å™¨

```bash
# æ›¿æ¢ä¸‹é¢ä¸¤ä¸ªå€¼
export BEARER_TOKEN="ä½ çš„BearerToken"
export CONFIG_ID="ä½ çš„ConfigID"

# è¿è¡Œ
docker run -d \
  --name gemini-proxy \
  --restart unless-stopped \
  -p 8080:8080 \
  -e BEARER_TOKEN="$BEARER_TOKEN" \
  -e CONFIG_ID="$CONFIG_ID" \
  -e TZ=Asia/Shanghai \
  ghcr.io/yourusername/gemini-proxy:latest
```

### 3ï¸âƒ£ æµ‹è¯•ä½¿ç”¨

```bash
# æµå¼å“åº”
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"gemini-2.5-flash","messages":[{"role":"user","content":"ä½ å¥½"}],"stream":true}'
```

## ðŸ³ Docker Compose æ–¹å¼

```bash
# åˆ›å»º docker-compose.yml
cat > docker-compose.yml << 'EOF'
version: '3.8'
services:
  gemini-proxy:
    image: ghcr.io/yourusername/gemini-proxy:latest
    container_name: gemini-proxy
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - BEARER_TOKEN=${BEARER_TOKEN}
      - CONFIG_ID=${CONFIG_ID}
      - TZ=Asia/Shanghai
EOF

# åˆ›å»º .env æ–‡ä»¶
cat > .env << EOF
BEARER_TOKEN=ä½ çš„BearerToken
CONFIG_ID=ä½ çš„ConfigID
EOF

# å¯åŠ¨
docker-compose up -d
```

## ðŸ“± Python å®¢æˆ·ç«¯

```python
import openai

openai.api_base = "http://localhost:8080/v1"
openai.api_key = "dummy"

response = openai.ChatCompletion.create(
    model="gemini-2.5-flash",
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    stream=True
)

for chunk in response:
    if hasattr(chunk.choices[0].delta, 'content'):
        print(chunk.choices[0].delta.content, end="", flush=True)
```

## ðŸ”§ å¸¸ç”¨å‘½ä»¤

```bash
# æŸ¥çœ‹æ—¥å¿—
docker logs -f gemini-proxy

# é‡å¯æœåŠ¡
docker restart gemini-proxy

# åœæ­¢æœåŠ¡
docker stop gemini-proxy

# åˆ é™¤å®¹å™¨
docker stop gemini-proxy && docker rm gemini-proxy
```

## âš ï¸ å¸¸è§é—®é¢˜

**Q: 401 é”™è¯¯ï¼Ÿ**
A: Bearer Token è¿‡æœŸæˆ–é”™è¯¯ï¼Œé‡æ–°èŽ·å–

**Q: 404 é”™è¯¯ï¼Ÿ**
A: Config ID é”™è¯¯ï¼Œä»ŽURLé‡æ–°èŽ·å–

**Q: è¿žæŽ¥è¶…æ—¶ï¼Ÿ**
A: æ£€æŸ¥ç½‘ç»œï¼Œæˆ–è®¾ç½® PROXY_URL çŽ¯å¢ƒå˜é‡

---

**å®Œæˆï¼** çŽ°åœ¨ä½ å¯ä»¥ä½¿ç”¨ OpenAI æ ¼å¼çš„ API è®¿é—® Gemini Business äº†ã€‚