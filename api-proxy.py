#!/usr/bin/env python3
"""
è½»é‡çº§APIä»£ç†æœåŠ¡ï¼ˆPythonç‰ˆæœ¬ï¼‰
æä¾›OpenAIæ ¼å¼çš„APIæ¥å£ï¼Œç›´æ¥è°ƒç”¨Gemini Business API
"""

import asyncio
import json
import os
import time
import aiohttp
from aiohttp import web
from datetime import datetime
from typing import Dict, List, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

logger = logging.getLogger(__name__)

# ç¯å¢ƒå˜é‡é…ç½®
class Config:
    BEARER_TOKEN = os.getenv('BEARER_TOKEN', '')
    CONFIG_ID = os.getenv('CONFIG_ID', '')
    PORT = int(os.getenv('PORT', '8080'))
    DEBUG = os.getenv('DEBUG', 'false').lower() == 'true'
    PROXY_URL = os.getenv('PROXY_URL', '')

config = Config()

# OpenAIæ ¼å¼è¯·æ±‚æ¨¡å‹
class OpenAIRequest:
    def __init__(self, data: Dict):
        self.model = data.get('model', 'gemini-2.5-flash')
        self.messages = data.get('messages', [])
        self.stream = data.get('stream', False)
        self.temperature = data.get('temperature', 0.7)
        self.max_tokens = data.get('max_tokens')
        self.user = data.get('user')

# Gemini APIè¯·æ±‚æ¨¡å‹
class GeminiRequest:
    def __init__(self, openai_req: OpenAIRequest):
        self.model = openai_req.model
        self.messages = openai_req.messages
        self.temperature = openai_req.temperature
        self.max_tokens = openai_req.max_tokens

# APIä»£ç†æœåŠ¡
class APIProxy:
    def __init__(self):
        self.base_url = "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetStreamAssist"
        self.session = None
    
    async def get_session(self):
        """è·å–HTTPä¼šè¯"""
        if not self.session:
            connector = aiohttp.TCPConnector(ssl=False)
            if config.PROXY_URL:
                connector = aiohttp.TCPConnector(ssl=False, proxy=config.PROXY_URL)
            self.session = aiohttp.ClientSession(connector=connector)
        return self.session
    
    def build_gemini_payload(self, gemini_req: GeminiRequest) -> Dict:
        """æ„å»ºGemini APIè¯·æ±‚ä½“"""
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        contents = []
        for msg in gemini_req.messages:
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            
            if role == 'system':
                # ç³»ç»Ÿæç¤ºè¯ä½œä¸ºé…ç½®
                continue
            elif role == 'user':
                contents.append({
                    "role": "user",
                    "parts": [{"text": content}]
                })
            elif role == 'assistant':
                contents.append({
                    "role": "model",
                    "parts": [{"text": content}]
                })
        
        payload = {
            "contents": contents,
            "generationConfig": {
                "temperature": gemini_req.temperature,
            }
        }
        
        if gemini_req.max_tokens:
            payload["generationConfig"]["maxOutputTokens"] = gemini_req.max_tokens
        
        return payload
    
    async def send_request(self, payload: Dict, stream: bool = False) -> aiohttp.ClientResponse:
        """å‘é€è¯·æ±‚åˆ°Gemini API"""
        session = await self.get_session()
        
        headers = {
            "Authorization": f"Bearer {config.BEARER_TOKEN}",
            "Content-Type": "application/json",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        # æ·»åŠ Config IDåˆ°URL
        url = f"{self.base_url}?configId={config.CONFIG_ID}"
        if stream:
            url += "&stream=true"
        
        if config.DEBUG:
            logger.info(f"å‘é€è¯·æ±‚åˆ°: {url}")
            logger.info(f"è¯·æ±‚ä½“: {json.dumps(payload, ensure_ascii=False)}")
        
        try:
            response = await session.post(
                url,
                json=payload,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=60)
            )
            return response
        except Exception as e:
            logger.error(f"è¯·æ±‚å¤±è´¥: {e}")
            raise
    
    async def handle_normal_chat(self, openai_req: OpenAIRequest) -> Dict:
        """å¤„ç†éæµå¼å“åº”"""
        gemini_req = GeminiRequest(openai_req)
        payload = self.build_gemini_payload(gemini_req)
        
        response = await self.send_request(payload, stream=False)
        
        if response.status != 200:
            error_text = await response.text()
            logger.error(f"Gemini APIé”™è¯¯: {response.status} - {error_text}")
            raise web.HTTPException(status_code=response.status, text=error_text)
        
        data = await response.json()
        
        # è½¬æ¢ä¸ºOpenAIæ ¼å¼
        return self._convert_to_openai_format(data, openai_req.model)
    
    async def handle_stream_chat(self, request: web.Request, openai_req: OpenAIRequest):
        """å¤„ç†æµå¼å“åº”"""
        gemini_req = GeminiRequest(openai_req)
        payload = self.build_gemini_payload(gemini_req)
        
        response = await self.send_request(payload, stream=True)
        
        if response.status != 200:
            error_text = await response.text()
            logger.error(f"Gemini APIé”™è¯¯: {response.status} - {error_text}")
            raise web.HTTPException(status_code=response.status, text=error_text)
        
        # è®¾ç½®å“åº”å¤´
        headers = {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
        }
        
        # åˆ›å»ºæµå¼å“åº”
        async def generate():
            buffer = ""
            async for line in response.content:
                chunk = line.decode('utf-8')
                buffer += chunk
                
                # æŒ‰JSONå—åˆ†å‰²
                while '\n' in buffer:
                    line, buffer = buffer.split('\n', 1)
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        # å°è¯•è§£æJSON
                        data = json.loads(line)
                        
                        # è½¬æ¢ä¸ºOpenAIæ ¼å¼
                        openai_chunk = self._convert_to_stream_chunk(data, openai_req.model)
                        if openai_chunk:
                            yield f"data: {json.dumps(openai_chunk, ensure_ascii=False)}\n\n"
                    except json.JSONDecodeError:
                        continue
            
            yield "data: [DONE]\n\n"
        
        return web.Response(
            body=generate(),
            headers=headers,
            status=200
        )
    
    def _convert_to_openai_format(self, gemini_data: Dict, model: str) -> Dict:
        """è½¬æ¢Geminiå“åº”ä¸ºOpenAIæ ¼å¼"""
        if not gemini_data or 'candidates' not in gemini_data:
            return {
                "id": f"chatcmpl-{int(time.time())}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": model,
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": "No response from Gemini"
                    },
                    "finish_reason": "stop"
                }],
                "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
            }
        
        candidate = gemini_data['candidates'][0]
        content = candidate.get('content', {})
        parts = content.get('parts', [])
        text = parts[0].get('text', '') if parts else ""
        
        return {
            "id": f"chatcmpl-{int(time.time())}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": model,
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": text
                },
                "finish_reason": candidate.get('finishReason', 'stop')
            }],
            "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
        }
    
    def _convert_to_stream_chunk(self, gemini_data: Dict, model: str) -> Optional[Dict]:
        """è½¬æ¢Geminiæµå¼å—ä¸ºOpenAIæ ¼å¼"""
        if not gemini_data or 'candidates' not in gemini_data:
            return None
        
        candidate = gemini_data['candidates'][0]
        content = candidate.get('content', {})
        parts = content.get('parts', [])
        
        if not parts:
            return None
        
        text = parts[0].get('text', '')
        
        return {
            "id": f"chatcmpl-{int(time.time())}",
            "object": "chat.completion.chunk",
            "created": int(time.time()),
            "model": model,
            "choices": [{
                "index": 0,
                "delta": {
                    "role": "assistant",
                    "content": text
                },
                "finish_reason": candidate.get('finishReason')
            }]
        }
    
    async def close(self):
        """å…³é—­ä¼šè¯"""
        if self.session:
            await self.session.close()

# WebæœåŠ¡å™¨
async def create_app():
    """åˆ›å»ºWebåº”ç”¨"""
    app = web.Application()
    proxy = APIProxy()
    
    async def health_check(request):
        """å¥åº·æ£€æŸ¥"""
        return web.json_response({
            "status": "ok",
            "timestamp": datetime.now().isoformat(),
            "config": {
                "has_token": bool(config.BEARER_TOKEN),
                "has_config_id": bool(config.CONFIG_ID),
                "debug": config.DEBUG
            }
        })
    
    async def list_models(request):
        """åˆ—å‡ºæ¨¡å‹"""
        models = [
            {"id": "gemini-2.5-flash", "object": "model", "created": 0, "owned_by": "google"},
            {"id": "gemini-2.5-pro", "object": "model", "created": 0, "owned_by": "google"},
            {"id": "gemini-3-flash-preview", "object": "model", "created": 0, "owned_by": "google"},
            {"id": "gemini-3-pro-preview", "object": "model", "created": 0, "owned_by": "google"}
        ]
        return web.json_response({"object": "list", "data": models})
    
    async def chat_completions(request):
        """èŠå¤©å®Œæˆç«¯ç‚¹"""
        start_time = time.time()
        
        try:
            data = await request.json()
            
            if config.DEBUG:
                logger.info(f"æ”¶åˆ°è¯·æ±‚: {json.dumps(data, ensure_ascii=False)}")
            
            openai_req = OpenAIRequest(data)
            
            # éªŒè¯é…ç½®
            if not config.BEARER_TOKEN:
                raise web.HTTPUnauthorized(text="Missing BEARER_TOKEN environment variable")
            if not config.CONFIG_ID:
                raise web.HTTPUnauthorized(text="Missing CONFIG_ID environment variable")
            
            # éªŒè¯æ¨¡å‹
            valid_models = ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-3-flash-preview", "gemini-3-pro-preview"]
            if openai_req.model not in valid_models:
                raise web.HTTPBadRequest(text=f"Invalid model. Valid models: {valid_models}")
            
            # å¤„ç†è¯·æ±‚
            if openai_req.stream:
                return await proxy.handle_stream_chat(request, openai_req)
            else:
                result = await proxy.handle_normal_chat(openai_req)
                duration = time.time() - start_time
                logger.info(f"è¯·æ±‚å®Œæˆ: model={openai_req.model}, duration={duration:.2f}s")
                return web.json_response(result)
        
        except json.JSONDecodeError:
            raise web.HTTPBadRequest(text="Invalid JSON")
        except Exception as e:
            logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {e}")
            raise web.HTTPException(status_code=500, text=str(e))
    
    # æ³¨å†Œè·¯ç”±
    app.router.add_get('/health', health_check)
    app.router.add_get('/v1/models', list_models)
    app.router.add_post('/v1/chat/completions', chat_completions)
    
    return app

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ¤– Gemini Business API ä»£ç†æœåŠ¡ (Python)")
    logger.info("=" * 60)
    
    # éªŒè¯é…ç½®
    if not config.BEARER_TOKEN:
        logger.error("âŒ æœªè®¾ç½® BEARER_TOKEN ç¯å¢ƒå˜é‡")
        return
    
    if not config.CONFIG_ID:
        logger.error("âŒ æœªè®¾ç½® CONFIG_ID ç¯å¢ƒå˜é‡")
        return
    
    logger.info(f"âœ… é…ç½®éªŒè¯é€šè¿‡")
    logger.info(f"   Config ID: {config.CONFIG_ID}")
    logger.info(f"   Debug: {config.DEBUG}")
    if config.PROXY_URL:
        logger.info(f"   Proxy: {config.PROXY_URL}")
    
    # å¯åŠ¨WebæœåŠ¡å™¨
    app = await create_app()
    
    logger.info(f"ğŸš€ æœåŠ¡å¯åŠ¨: http://0.0.0.0:{config.PORT}")
    logger.info(f"   å¥åº·æ£€æŸ¥: http://localhost:{config.PORT}/health")
    logger.info(f"   APIç«¯ç‚¹: http://localhost:{config.PORT}/v1/chat/completions")
    logger.info("")
    logger.info("ç­‰å¾…è¯·æ±‚...")
    
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', config.PORT)
    await site.start()
    
    # ä¿æŒè¿è¡Œ
    try:
        await asyncio.Event().wait()
    except KeyboardInterrupt:
        logger.info("\nğŸ‘‹ æœåŠ¡æ­£åœ¨å…³é—­...")
    finally:
        await runner.cleanup()

if __name__ == "__main__":
    asyncio.run(main())